#!/usr/bin/env python3
# /// script
# dependencies = [
#   "PyYAML==6.*",
#   "ast-grep-py",
# ]
# requires-python = ">=3.10"
# ///

import argparse
import concurrent.futures
import sys
import pathlib
import re

# get string literals from the c++ source files
import ast_grep_py
from ast_grep_py import SgRoot

# ast-grep rules with nice syntax vs. nested dict()s
import yaml

# usually this gets called when patching GCC
DEFAULT_ROOT = pathlib.Path(__file__).parent / "repo/gcc-gnu/libstdc++-v3/include"

# any time rules below match, this header gets injected
# TODO make sure patches/ has Makefile.in modifications
#      otherwise, it never gets installed
# TODO libstd includes pre c++11 string lib for compatibility reasons
#      script values injected below need to be careful with the syntax
HELPER_HEADER = "__eqt/excstring.hpp"
HELPER_HEADER_SRC = """
/**
!!! AUTOMATICALLY GENERATED by the esp-quick-toolchain build script !!!
*/

#pragma once

#define __EQT_EXCSTR_CONCAT_IMPL(X, Y, Z) X ## Y ## Z
#define __EQT_EXCSTR_CONCAT(X, Y, Z) __EQT_EXCSTR_CONCAT_IMPL(X, Y, Z)
#define __EQT_EXCSTR_ATTR __attribute__((section(".irom.exceptiontext"))) __attribute__((aligned(4)))

#if (__cplusplus >= 201103L)
#define __EQT_EXCSTR_CONSTEXPR constexpr
#else
#define __EQT_EXCSTR_CONSTEXPR const
#endif

#define __EQT_EXCSTR_DECL(NAME, s)\
    static __EQT_EXCSTR_CONSTEXPR char NAME [] __EQT_EXCSTR_ATTR = s

#define __EQT_EXCSTR_WRAP(NAME, s) (({ __EQT_EXCSTR_DECL(NAME, s); &NAME[0]; }))
#define __EQT_EXCSTR_NAME(X) __EQT_EXCSTR_CONCAT(X, __LINE__, __COUNTER__)

#define __EQT_EXCSTR(s)\
    __EQT_EXCSTR_WRAP(__EQT_EXCSTR_NAME(__exception_what__), s)
"""

# generic exception interface override
WHAT_RULE = """
utils:
  finder:
    any:
      - matches: find-string
      - matches: find-concatenated-string

  localizable-macro:
    kind: argument_list
    inside:
      kind: call_expression
      pattern:
        context: __N($$$)
      inside:
        matches: return-statement

  return-statement:
    kind: return_statement
    inside:
      kind: compound_statement
      inside:
        kind: function_definition
        regex: ::what()|what()

  find-string:
    kind: string_literal
    inside:
      any:
        - matches: localizable-macro
        - matches: return-statement

  find-concatenated-string:
    kind: concatenated_string
    inside:
      kind: argument_list
      inside:
        any:
          - matches: localizable-macro
          - matches: return-statement

rule:
  matches: finder
"""

# throwing from utility funcs
THROWING_RULE_TMPL = """
utils:
  finder:
    any:
      - matches: find-string
      - matches: find-concatenated-string

  throwing-function:
    kind: call_expression
    pattern:
      context: %%NAME%%($$$)

  localizable-macro:
    kind: argument_list
    inside:
      kind: call_expression
      pattern:
        context: __N($$$)
      inside:
        kind: argument_list
        inside:
          matches: throwing-function

  find-string:
    kind: string_literal
    inside:
      kind: argument_list
      inside:
        any:
          - matches: localizable-macro
          - matches: throwing-function

  find-concatenated-string:
    kind: concatenated_string
    inside:
      kind: argument_list
      inside:
        any:
          - matches: localizable-macro
          - matches: throwing-function

rule:
  matches: finder
"""

# manually extracted via `git grep '__throw.*(const char'`
THROWING_FUNC_NAMES = [
    # std/optional
    "__throw_bad_optional_access",
    # std/variant
    "__throw_bad_variant_access",
    # std/format
    "__throw_format_error",
    # bits/regex.h
    "__throw_regex_error",
    # bits/functexcept.h
    "__throw_domain_error",
    "__throw_invalid_argument",
    "__throw_ios_failure",
    "__throw_length_error",
    "__throw_logic_error",
    "__throw_on_error",
    "__throw_out_of_range",
    "__throw_out_of_range_fmt",
    "__throw_overflow_error",
    "__throw_range_error",
    "__throw_runtime_error",
    "__throw_underflow_error",
]


# declarations must be placed where they would actually be used
NS_INSERT_ANCHORS = [
    "namespace __gnu_cxx _GLIBCXX_VISIBILITY(default)",
    "namespace std _GLIBCXX_VISIBILITY(default)",
]


def make_throwing_rule(name):
    raw = THROWING_RULE_TMPL.replace("%%NAME%%", name)
    return yaml.load(raw, Loader=yaml.CLoader)


def is_ignored(p: pathlib.Path) -> bool:
    match p.suffix:
        case ".h" | ".hpp" | ".tpp":
            return False
        case "":
            return False

    return True


def format_decl(name: str, text: str) -> str:
    return f"__EQT_EXCSTR_DECL({name}, {text});"


# for the sake of coherency, preserve __N(...) msgids
def maybe_swap_localizable_node(
    node: ast_grep_py.SgNode, text: str
) -> tuple[ast_grep_py.SgNode, str]:
    parent = node.parent()
    if not parent:
        raise ValueError()

    parent = parent.parent()
    if not parent:
        raise ValueError()

    parent = parent.parent()
    if not parent:
        raise ValueError()

    if parent.text().startswith("__N("):
        node = parent
        text = f"__N({text})"

    return (node, text)


# processes given string literal / concatenated string node and prepares the required file edits
class Worker:
    decls: list[str]
    edits: list[ast_grep_py.Edit]

    _known: dict[str, dict[str, str]]

    def __init__(self, tag: str):
        self.decls = []
        self.edits = []

        self._tag = tag
        self._known = {}

    def pending(self):
        return (len(self.edits) > 0) and (len(self.decls) > 0)

    def process(self, tag: str, node: ast_grep_py.SgNode):
        match node.kind():
            # result.text() includes \n and spacing
            case "concatenated_string":
                text = ""
                for child in node.children():
                    text += child.text().replace('"', "")
                text = f'"{text}"'

            # literal usable as-is
            case "string_literal":
                text = node.text()

        # do not duplicate var->text declarations
        if not tag in self._known:
            self._known[tag] = {}
        ref = self._known[tag]

        exists = ref.get(text)
        if exists:
            name = exists
        else:
            index = len(ref.keys())
            name = f"__eqt_excstr_{tag}_{self._tag}{index}"
            ref[text] = name

        if not exists:
            self.decls.append(format_decl(name, text))

        node, text = maybe_swap_localizable_node(node, text)
        self.edits.append(node.replace(name))


def worker(root: pathlib.Path, p: pathlib.Path, tagged_rules):
    with p.open("r") as f:
        data = f.read()

    if HELPER_HEADER in data:
        return (p, None)

    file_tag = re.sub(r"\W+", "_", p.relative_to(root).as_posix())

    inst = Worker(file_tag)

    sg_root = SgRoot(data, "c++")

    node = sg_root.root()
    for tag, rules in tagged_rules.items():
        for rule in rules:
            for result in node.find_all(rule):
                inst.process(tag, result)

    def find_insert_anchor(data) -> tuple[str | None, int]:
        for m in NS_INSERT_ANCHORS:
            count = data.count(m)
            if count:
                return (m, count)

        return (None, 0)

    def prepare_decls(decls: list[str], anchor: str) -> str:
        return "\n".join(
            [
                f"#include <{HELPER_HEADER}>",
                "",
                "namespace {",
                "",
                "\n".join(decls),
                "",
                "} // namespace",
                "",
                anchor,
            ]
        )

    if inst.pending():
        out = node.commit_edits(inst.edits)

        anchor, count = find_insert_anchor(out)
        if not anchor:
            raise ValueError(f"{p} has no suitable anchor")

        if count > 2:
            raise ValueError(f'{p} has no more than one anchor "{anchor}"')

        sub = prepare_decls(inst.decls, anchor)
        return (p, out.replace(anchor, sub))


RULES = {
    "what": [yaml.load(WHAT_RULE, Loader=yaml.CLoader)],
    "throw": [make_throwing_rule(name) for name in THROWING_FUNC_NAMES],
}


# usually we want everything in the directoy
# note that the path root is later used for name generation based on relative path
def find_files(path_root):
    for root, dir, files in path_root.walk():
        for file in files:
            p = root / file
            if is_ignored(p):
                continue

            yield p


# gets injected here, not through patches/
def write_or_replace_helper_header(p: pathlib.Path):
    try:
        with p.open("r") as f:
            data = f.read()

        if data == HELPER_HEADER_SRC:
            return
    except:
        pass

    with p.open("w") as f:
        f.write(HELPER_HEADER_SRC)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument(
        "--root", type=pathlib.Path, default=DEFAULT_ROOT
    )
    parser.add_argument(
        "--output", type=argparse.FileType('w'), default=sys.stdout, help="logging output"
    )
    args = parser.parse_args()

    write_or_replace_helper_header(args.root / HELPER_HEADER)

    executor = concurrent.futures.ProcessPoolExecutor()
    with executor as e:
        futures: list[concurrent.futures.Future] = []
        for p in find_files(args.root):
            futures.append(e.submit(worker, args.root, p, RULES))
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            if not result:
                continue

            p, data = result
            if not data:
                print(f'{p} already modified', file=args.output)
                continue

            print(p, file=args.output)
            with p.open("w") as f:
                f.write(data)
