#!/usr/bin/env python3
# /// script
# dependencies = [
#   "PyYAML==6.*",
#   "ast-grep-py",
# ]
# requires-python = ">=3.8"
# ///

from typing import Tuple, List, Dict, Optional

import os
import warnings
import argparse
import concurrent.futures
import sys
import pathlib
import re

# get string literals from the c++ source files
import ast_grep_py
from ast_grep_py import SgRoot

# ast-grep rules with nice syntax vs. nested dict()s
import yaml

# usually this gets called when patching GCC
DEFAULT_ROOT = pathlib.Path(__file__).parent / "repo/gcc-gnu/libstdc++-v3/include"

# any time rules below match, this header gets injected
# TODO make sure patches/ has Makefile.in modifications
#      otherwise, it never gets installed
# TODO libstd includes pre c++11 string lib for compatibility reasons
#      script values injected below need to be careful with the syntax
HELPER_HEADER = "__eqt/excstring.hpp"
HELPER_HEADER_SRC = """
/**
!!! AUTOMATICALLY GENERATED by the esp-quick-toolchain build script !!!
*/

#pragma once

#define __EQT_EXCSTR_CONCAT_IMPL(X, Y, Z) X ## Y ## Z
#define __EQT_EXCSTR_CONCAT(X, Y, Z) __EQT_EXCSTR_CONCAT_IMPL(X, Y, Z)
#define __EQT_EXCSTR_ATTR __attribute__((section(".irom.exceptiontext"))) __attribute__((aligned(4)))

#if (__cplusplus >= 201103L)
#define __EQT_EXCSTR_CONSTEXPR constexpr
#else
#define __EQT_EXCSTR_CONSTEXPR const
#endif

#define __EQT_EXCSTR_DECL(NAME, s)\
    static __EQT_EXCSTR_CONSTEXPR char NAME [] __EQT_EXCSTR_ATTR = s

#define __EQT_EXCSTR_WRAP(NAME, s) (({ __EQT_EXCSTR_DECL(NAME, s); &NAME[0]; }))
#define __EQT_EXCSTR_NAME(X) __EQT_EXCSTR_CONCAT(X, __LINE__, __COUNTER__)

#define __EQT_EXCSTR(s)\
    __EQT_EXCSTR_WRAP(__EQT_EXCSTR_NAME(__exception_what__), s)
"""

# generic exception interface override
WHAT_RULE = """
utils:
  finder:
    any:
      - matches: find-string
      - matches: find-concatenated-string

  localizable-macro:
    kind: argument_list
    inside:
      kind: call_expression
      pattern:
        context: __N($$$)
      inside:
        matches: return-statement

  return-statement:
    kind: return_statement
    inside:
      kind: compound_statement
      inside:
        kind: function_definition
        regex: ::what()|what()

  find-string:
    kind: string_literal
    inside:
      any:
        - matches: localizable-macro
        - matches: return-statement

  find-concatenated-string:
    kind: concatenated_string
    inside:
      kind: argument_list
      inside:
        any:
          - matches: localizable-macro
          - matches: return-statement

rule:
  matches: finder
"""

# throwing from utility funcs
THROWING_RULE_TMPL = r"""
utils:
  finder:
    any:
      - matches: find-string
      - matches: find-concatenated-string

  throwing-function:
    kind: call_expression
    regex: %%NAME%%\(

  localizable-macro:
    kind: argument_list
    inside:
      kind: call_expression
      pattern:
        context: __N($$$)
      inside:
        kind: argument_list
        inside:
          matches: throwing-function

  find-string:
    kind: string_literal
    inside:
      kind: argument_list
      inside:
        any:
          - matches: localizable-macro
          - matches: throwing-function

  find-concatenated-string:
    kind: concatenated_string
    inside:
      any:
        - matches: localizable-macro
        - matches: throwing-function

rule:
  matches: finder
"""

# manually extracted via `git grep '__throw.*(const char'`
# nb. sometimes it is std::..., sometimes as-is.
# rule should match both naming convetions
THROWING_FUNC_NAMES = [
    # std/optional
    "__throw_bad_optional_access",
    # std/variant
    "__throw_bad_variant_access",
    # std/format
    "__throw_format_error",
    # bits/regex.h
    "__throw_regex_error",
    # bits/functexcept.h
    "__throw_domain_error",
    "__throw_invalid_argument",
    "__throw_ios_failure",
    "__throw_length_error",
    "__throw_logic_error",
    "__throw_on_error",
    "__throw_out_of_range",
    "__throw_out_of_range_fmt",
    "__throw_overflow_error",
    "__throw_range_error",
    "__throw_runtime_error",
    "__throw_underflow_error",
]


# declarations must be placed where they would actually be used
NS_INSERT_ANCHORS = [
    "namespace __gnu_cxx _GLIBCXX_VISIBILITY(default)",
    "namespace std _GLIBCXX_VISIBILITY(default)",
]


def make_throwing_rule(name):
    return yaml.load(THROWING_RULE_TMPL.replace("%%NAME%%", name), Loader=yaml.CLoader)


def is_ignored(p: pathlib.Path) -> bool:
    if p.suffix in [".h", ".hpp", ".tpp"]:
        return False
    elif p.suffix == "":
        return False

    return True


def format_decl(name: str, text: str) -> str:
    return f"__EQT_EXCSTR_DECL({name}, {text});"


# for the sake of coherency, preserve __N(...) msgids
def maybe_swap_localizable_node(
    node: ast_grep_py.SgNode, text: str
) -> Tuple[ast_grep_py.SgNode, str]:
    parent = node.parent()
    if not parent:
        raise ValueError()

    parent = parent.parent()
    if not parent:
        raise ValueError()

    parent = parent.parent()
    if not parent:
        raise ValueError()

    if parent.text().startswith("__N("):
        node = parent
        text = f"__N({text})"

    return (node, text)


# processes given string literal / concatenated string node and prepares the required file edits
class Worker:
    decls: List[str]
    edits: List[ast_grep_py.Edit]

    _known: Dict[str, Dict[str, str]]

    def __init__(self, tag: str):
        self.decls = []
        self.edits = []

        self._tag = tag
        self._known = {}

    def pending(self):
        return (len(self.edits) > 0) and (len(self.decls) > 0)

    def process(self, tag: str, node: ast_grep_py.SgNode):
        kind = node.kind()

        # result.text() includes \n and spacing
        if kind == "concatenated_string":
            text = ""
            for child in node.children():
                text += child.text().replace('"', "")
            text = f'"{text}"'

        # literal usable as-is
        elif kind == "string_literal":
            text = node.text()

        # do not duplicate var->text declarations
        if not tag in self._known:
            self._known[tag] = {}
        ref = self._known[tag]

        exists = ref.get(text)
        if exists:
            name = exists
        else:
            name = f"__eqt_excstr_{tag}_{self._tag}{len(ref)}"
            ref[text] = name

        if not exists:
            self.decls.append(format_decl(name, text))

        node, text = maybe_swap_localizable_node(node, text)
        self.edits.append(node.replace(name))


def worker(root: pathlib.Path, p: pathlib.Path, tagged_rules):
    with p.open("r") as f:
        data = f.read()

    if HELPER_HEADER in data:
        return (p, None)

    file_tag = re.sub(r"\W+", "_", p.relative_to(root).as_posix())

    inst = Worker(file_tag)

    sg_root = SgRoot(data, "c++")

    node = sg_root.root()
    for tag, rules in tagged_rules.items():
        for rule in rules:
            for result in node.find_all(rule):
                inst.process(tag, result)

    def find_insert_anchor(data) -> Optional[str]:
        found = {}

        for m in NS_INSERT_ANCHORS:
            try:
                found[m] = (
                    data.index(m),
                    data.count(m),
                )
            except ValueError:
                pass

        items = found.items()
        if not items:
            return None

        indexed = sorted(items, key=lambda x: x[1][0])
        anchor, (index, count) = indexed[0]

        # XXX known headers, known to work
        if count > 2 and not p.name in ["basic_string.h"]:
            warnings.warn(f'{p} has more than one anchor "{anchor}"')

        return anchor

    def prepare_decls(decls: List[str], anchor: str) -> str:
        return "\n".join(
            [
                f"#include <{HELPER_HEADER}>",
                "",
                "namespace {",
                "",
                "\n".join(decls),
                "",
                "} // namespace",
                "",
                anchor,
            ]
        )

    if inst.pending():
        out = node.commit_edits(inst.edits)

        anchor = find_insert_anchor(data)
        if not anchor:
            raise ValueError(f"{p} found no suitable anchor")

        sub = prepare_decls(inst.decls, anchor)
        return (p, out.replace(anchor, sub, 1))


RULES = {
    "what": [yaml.load(WHAT_RULE, Loader=yaml.CLoader)],
    "throw": [make_throwing_rule(name) for name in THROWING_FUNC_NAMES],
}


def os_walk(path_root: pathlib.Path):
    for path_str, dirnames, filenames in os.walk(path_root.as_posix()):
        if path_root == ".":
            path_str = path_str[2:]
        yield pathlib.Path(path_str), dirnames, filenames


def pathlib_walk(path_root: pathlib.Path):
    return path_root.walk()


def walk(path_root: pathlib.Path):
    if sys.version_info >= (3, 12):
        return pathlib_walk(path_root)

    return os_walk(path_root)


# usually we want everything in the directoy
# note that the path root is later used for name generation based on relative path
def find_files(path_root):
    for root, dir, files in walk(path_root):
        for file in files:
            p = root / file
            if is_ignored(p):
                continue

            yield p


# gets injected here, not through patches/
def write_or_replace_helper_header(p: pathlib.Path):
    try:
        with p.open("r") as f:
            data = f.read()

        if data == HELPER_HEADER_SRC:
            return
    except:
        pass

    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(HELPER_HEADER_SRC)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )
    parser.add_argument("--root", type=pathlib.Path, default=DEFAULT_ROOT)
    parser.add_argument(
        "--output",
        type=argparse.FileType("w"),
        default=sys.stdout,
        help="logging output",
    )
    args = parser.parse_args()

    write_or_replace_helper_header(args.root / HELPER_HEADER)

    executor = concurrent.futures.ProcessPoolExecutor()
    with executor as e:
        futures = [e.submit(worker, args.root, p, RULES) for p in find_files(args.root)]
        for future in concurrent.futures.as_completed(futures):
            result = future.result()
            if not result:
                continue

            p, data = result
            if not data:
                print(f"{p} already modified", file=args.output)
                continue

            print(f"Modifying {p}", file=args.output)
            with p.open("w") as f:
                f.write(data)
